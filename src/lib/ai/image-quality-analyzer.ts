import {
  ImageQualityScore,
  ImageQualityAnalysisResult,
  BatchQualityAnalysisResult,
  ImageQualityAnalysisOptions,
  getQualityStatus,
  CriticalIssue,
  MinorIssue
} from '@/types/image-quality'
import { AI_CONFIG } from './config'

/**
 * Image Quality Analyzer for Fine-Tuning Photos
 * Uses OpenAI GPT-4o Vision API to analyze photos for AI model training
 * Checks for: glasses, sunglasses, blur, multiple people, headwear, etc.
 */

interface OpenAIVisionResponse {
  choices: Array<{
    message: {
      content: string
    }
  }>
}

export class ImageQualityAnalyzer {
  private apiKey: string
  private model: string
  private endpoint: string

  constructor() {
    if (!AI_CONFIG.openai.apiKey) {
      throw new Error('OPENAI_API_KEY not configured')
    }
    this.apiKey = AI_CONFIG.openai.apiKey
    this.model = AI_CONFIG.openai.model
    this.endpoint = AI_CONFIG.openai.endpoint
  }

  /**
   * Analyze a single image for quality and fine-tuning readiness
   */
  async analyzeImage(
    imageData: string,
    filename: string,
    options: ImageQualityAnalysisOptions
  ): Promise<ImageQualityAnalysisResult> {
    const startTime = Date.now()

    try {
      console.log(`üîç Analyzing with OpenAI GPT-4o: ${filename} (${options.photoType})`)

      // Build the analysis prompt
      const prompt = this.buildAnalysisPrompt(options)

      // Call OpenAI API with base64 image
      const response = await fetch(this.endpoint, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`
        },
        body: JSON.stringify({
          model: this.model,
          messages: [
            {
              role: 'user',
              content: [
                {
                  type: 'text',
                  text: prompt
                },
                {
                  type: 'image_url',
                  image_url: {
                    url: imageData // Already in data:image/jpeg;base64,... format
                  }
                }
              ]
            }
          ],
          max_tokens: AI_CONFIG.openai.maxTokens,
          temperature: AI_CONFIG.openai.temperature
        })
      })

      if (!response.ok) {
        const errorText = await response.text()
        console.error('‚ùå OpenAI API error:', errorText)
        throw new Error(`OpenAI API error: ${response.status}`)
      }

      const data: OpenAIVisionResponse = await response.json()
      const content = data.choices[0]?.message?.content

      if (!content) {
        throw new Error('Empty response from OpenAI')
      }

      console.log(`üìä OpenAI response for ${filename}:`, content.substring(0, 200))

      // Parse JSON response
      const jsonMatch = content.match(/\{[\s\S]*\}/)
      if (!jsonMatch) {
        throw new Error('No JSON found in OpenAI response')
      }

      const qualityScore: ImageQualityScore = JSON.parse(jsonMatch[0])
      const processingTime = Date.now() - startTime

      const result: ImageQualityAnalysisResult = {
        filename,
        quality: qualityScore,
        isAcceptable: qualityScore.score >= 50,
        isRecommended: qualityScore.score >= 70,
        processingTime
      }

      console.log(`‚úÖ Analysis complete: ${filename} - Score: ${qualityScore.score}`)

      return result

    } catch (error) {
      console.error(`‚ùå Error analyzing ${filename}:`, error)
      const processingTime = Date.now() - startTime

      return {
        filename,
        quality: {
          score: 0,
          technicalQuality: 0,
          composition: 0,
          finetuningReadiness: 0,
          criticalIssues: [],
          minorIssues: [],
          feedback: 'Erro ao analisar a imagem.',
          recommendations: ['Verifique se a imagem n√£o est√° corrompida.'],
          status: 'poor'
        },
        isAcceptable: false,
        isRecommended: false,
        processingTime
      }
    }
  }

  /**
   * Analyze multiple images in batch
   */
  async analyzeImages(
    images: Array<{ data: string; filename: string }>,
    options: ImageQualityAnalysisOptions
  ): Promise<BatchQualityAnalysisResult> {
    const startTime = Date.now()
    console.log(`üì¶ Analyzing ${images.length} images with OpenAI GPT-4o...`)

    const results: ImageQualityAnalysisResult[] = []

    for (const image of images) {
      const result = await this.analyzeImage(image.data, image.filename, options)
      results.push(result)
      // Small delay to avoid rate limiting
      await new Promise(resolve => setTimeout(resolve, 500))
    }

    const totalProcessingTime = Date.now() - startTime
    const averageScore = results.reduce((sum, r) => sum + r.quality.score, 0) / results.length
    const acceptableCount = results.filter(r => r.isAcceptable).length
    const recommendedCount = results.filter(r => r.isRecommended).length

    console.log(`‚úÖ Batch complete: ${results.length} images in ${totalProcessingTime}ms`)
    console.log(`üìä Average: ${averageScore.toFixed(1)}, Acceptable: ${acceptableCount}/${results.length}`)

    return {
      results,
      summary: {
        totalImages: images.length,
        averageScore,
        acceptableCount,
        recommendedCount,
        processingTime: totalProcessingTime
      }
    }
  }

  /**
   * Build the analysis prompt based on photo type
   */
  private buildAnalysisPrompt(options: ImageQualityAnalysisOptions): string {
    const { photoType, modelClass } = options

    const subjectType = modelClass === 'ANIMAL' ? 'animal' : 'pessoa'
    const photoDescription = this.getPhotoTypeDescription(photoType)

    return `Voc√™ √© um especialista em an√°lise de fotos para fine-tuning de modelos de IA (FLUX, Stable Diffusion).

Analise esta foto de ${photoDescription} e avalie se ela √© adequada para treinar um modelo de IA personalizado de ${subjectType}.

CRIT√âRIOS DE AVALIA√á√ÉO:

1. QUALIDADE T√âCNICA (0-25 pontos):
   - Nitidez e foco adequados
   - Ilumina√ß√£o balanceada (sem sombras duras ou superexposi√ß√£o)
   - Resolu√ß√£o suficiente (m√≠nimo 512x512, ideal 1024x1024+)
   - Sem artefatos de compress√£o ou ru√≠do excessivo

2. COMPOSI√á√ÉO (0-25 pontos):
   - ${subjectType === 'pessoa' ? 'Pessoa' : 'Animal'} centralizado(a) e bem enquadrado(a)
   - Fundo n√£o muito distrativo ou confuso
   - Dist√¢ncia adequada da c√¢mera (nem muito longe, nem muito perto)
   - Pose n√£o cortada (corpo completo vis√≠vel para fotos de corpo inteiro)

3. ADEQUA√á√ÉO PARA FINE-TUNING (0-50 pontos) - MAIS IMPORTANTE:

   PROBLEMAS CR√çTICOS que prejudicam MUITO o treinamento:
   ${subjectType === 'pessoa' ? `
   ‚ùå Bon√©, chap√©u, gorro ou qualquer coisa cobrindo a cabe√ßa/cabelo
   ‚ùå √ìculos escuros (√≥culos de grau transparente s√£o OK se a pessoa usa sempre)
   ‚ùå M√°scaras faciais, cachec√≥is ou m√£os cobrindo o rosto
   ‚ùå Outras pessoas vis√≠veis na foto (mesmo parcialmente ou ao fundo)
   ‚ùå Caretas, l√≠ngua para fora, olhos fechados ou piscando
   ‚ùå Express√µes muito extremas ou n√£o naturais
   ‚ùå Filtros pesados (Instagram, Snapchat, beautify)
   ‚ùå √Çngulos muito extremos (muito de cima, muito de baixo, perfil completo)
   ` : `
   ‚ùå M√∫ltiplos animais na foto
   ‚ùå Pessoas muito vis√≠veis junto com o animal
   ‚ùå Animal com acess√≥rios exagerados (fantasias, roupas muito chamativas)
   ‚ùå Animal dormindo ou com olhos fechados
   `}

   ‚úÖ FOTO IDEAL: ${subjectType} sozinho(a), ${subjectType === 'pessoa' ? 'rosto descoberto, sem acess√≥rios que cubram caracter√≠sticas faciais (cabelo, olhos, sobrancelhas)' : 'animal em destaque'}, express√£o/pose natural, boa ilumina√ß√£o, sem filtros, fundo simples

IMPORTANTE: Seja RIGOROSO com acess√≥rios que cobrem o rosto (bon√©s, chap√©us, √≥culos escuros). Estes s√£o os problemas MAIS GRAVES pois impedem o modelo de aprender caracter√≠sticas faciais corretamente.

Responda APENAS em JSON v√°lido (sem markdown, sem \`\`\`json):
{
  "score": <n√∫mero 0-100>,
  "technicalQuality": <n√∫mero 0-25>,
  "composition": <n√∫mero 0-25>,
  "finetuningReadiness": <n√∫mero 0-50>,
  "criticalIssues": [<array de strings: "hat_or_cap", "sunglasses", "face_covered", "multiple_people", "making_faces", "eyes_closed", "heavy_filters", "hand_covering_face", "extreme_angle", "mask">],
  "minorIssues": [<array de strings: "slight_blur", "low_light", "busy_background", "low_resolution", "overexposed", "underexposed", "artifacts", "poor_framing">],
  "feedback": "<texto curto em portugu√™s (max 150 caracteres) explicando a avalia√ß√£o geral>",
  "recommendations": [<array com 1-3 recomenda√ß√µes espec√≠ficas em portugu√™s para melhorar a foto, se houver problemas>]
}`
  }

  /**
   * Get photo type description in Portuguese
   */
  private getPhotoTypeDescription(photoType: string): string {
    switch (photoType) {
      case 'face':
        return 'rosto (close-up do rosto)'
      case 'half_body':
        return 'meio corpo (da cintura para cima)'
      case 'full_body':
        return 'corpo inteiro'
      default:
        return 'rosto'
    }
  }
}

// Singleton instance for use across the application
export const imageQualityAnalyzer = new ImageQualityAnalyzer()
