import {
  ImageQualityScore,
  ImageQualityAnalysisResult,
  BatchQualityAnalysisResult,
  ImageQualityAnalysisOptions,
  getQualityStatus,
  CriticalIssue,
  MinorIssue
} from '@/types/image-quality'
import { AI_CONFIG } from './config'

/**
 * Image Quality Analyzer for Fine-Tuning Photos
 * Uses OpenAI GPT-4o Vision API to analyze photos for AI model training
 * Checks for: glasses, sunglasses, blur, multiple people, headwear, etc.
 */

interface OpenAIVisionResponse {
  choices: Array<{
    message: {
      content: string
    }
  }>
}

export class ImageQualityAnalyzer {
  private apiKey: string
  private model: string
  private endpoint: string

  constructor() {
    if (!AI_CONFIG.openai.apiKey) {
      throw new Error('OPENAI_API_KEY not configured')
    }
    this.apiKey = AI_CONFIG.openai.apiKey
    this.model = AI_CONFIG.openai.model
    this.endpoint = AI_CONFIG.openai.endpoint
  }

  /**
   * Analyze a single image for quality and fine-tuning readiness
   */
  async analyzeImage(
    imageData: string,
    filename: string,
    options: ImageQualityAnalysisOptions
  ): Promise<ImageQualityAnalysisResult> {
    const startTime = Date.now()

    try {
      console.log(`üîç Analyzing with OpenAI GPT-4o: ${filename} (${options.photoType})`)

      // Build the analysis prompt
      const prompt = this.buildAnalysisPrompt(options)

      // Call OpenAI API with base64 image
      const response = await fetch(this.endpoint, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`
        },
        body: JSON.stringify({
          model: this.model,
          messages: [
            {
              role: 'user',
              content: [
                {
                  type: 'text',
                  text: prompt
                },
                {
                  type: 'image_url',
                  image_url: {
                    url: imageData // Already in data:image/jpeg;base64,... format
                  }
                }
              ]
            }
          ],
          max_tokens: AI_CONFIG.openai.maxTokens,
          temperature: AI_CONFIG.openai.temperature
        })
      })

      if (!response.ok) {
        const errorText = await response.text()
        console.error('‚ùå OpenAI API error:', errorText)
        throw new Error(`OpenAI API error: ${response.status}`)
      }

      const data: OpenAIVisionResponse = await response.json()
      const content = data.choices[0]?.message?.content

      if (!content) {
        throw new Error('Empty response from OpenAI')
      }

      console.log(`üìä OpenAI response for ${filename}:`, content.substring(0, 200))

      // Parse JSON response
      const jsonMatch = content.match(/\{[\s\S]*\}/)
      if (!jsonMatch) {
        throw new Error('No JSON found in OpenAI response')
      }

      const apiResponse = JSON.parse(jsonMatch[0])
      const processingTime = Date.now() - startTime

      // Build quality score with new simplified format + legacy fields
      const qualityScore: ImageQualityScore = {
        hasIssues: apiResponse.hasIssues || false,
        criticalIssues: apiResponse.criticalIssues || [],
        minorIssues: apiResponse.minorIssues || [],
        issuesSummary: apiResponse.issuesSummary,
        // Legacy fields for backward compatibility
        score: apiResponse.hasIssues ? 30 : 95,
        technicalQuality: 20,
        composition: 20,
        finetuningReadiness: apiResponse.hasIssues ? 10 : 45,
        feedback: apiResponse.issuesSummary || 'Foto adequada para treinamento',
        recommendations: apiResponse.hasIssues && apiResponse.issuesSummary
          ? [`Substitua esta foto: ${apiResponse.issuesSummary}`]
          : ['Foto aprovada'],
        status: apiResponse.hasIssues ? 'poor' : 'excellent'
      }

      const result: ImageQualityAnalysisResult = {
        filename,
        quality: qualityScore,
        isAcceptable: !apiResponse.hasIssues,
        isRecommended: !apiResponse.hasIssues,
        processingTime
      }

      console.log(`‚úÖ Analysis complete: ${filename} - ${apiResponse.hasIssues ? '‚ö†Ô∏è Issues found' : '‚úì OK'}`)

      return result

    } catch (error) {
      console.error(`‚ùå Error analyzing ${filename}:`, error)
      const processingTime = Date.now() - startTime

      return {
        filename,
        quality: {
          hasIssues: true,
          criticalIssues: [],
          minorIssues: [],
          issuesSummary: 'Erro ao analisar',
          score: 0,
          technicalQuality: 0,
          composition: 0,
          finetuningReadiness: 0,
          feedback: 'Erro ao analisar a imagem.',
          recommendations: ['Verifique se a imagem n√£o est√° corrompida.'],
          status: 'poor'
        },
        isAcceptable: false,
        isRecommended: false,
        processingTime
      }
    }
  }

  /**
   * Analyze multiple images in batch
   */
  async analyzeImages(
    images: Array<{ data: string; filename: string }>,
    options: ImageQualityAnalysisOptions
  ): Promise<BatchQualityAnalysisResult> {
    const startTime = Date.now()
    console.log(`üì¶ Analyzing ${images.length} images with OpenAI GPT-4o...`)

    const results: ImageQualityAnalysisResult[] = []

    for (const image of images) {
      const result = await this.analyzeImage(image.data, image.filename, options)
      results.push(result)
      // Small delay to avoid rate limiting
      await new Promise(resolve => setTimeout(resolve, 500))
    }

    const totalProcessingTime = Date.now() - startTime
    const photosWithIssues = results.filter(r => r.quality.hasIssues).length
    const photosOk = results.length - photosWithIssues

    console.log(`‚úÖ Batch complete: ${results.length} images in ${totalProcessingTime}ms`)
    console.log(`üìä Photos OK: ${photosOk}, With issues: ${photosWithIssues}`)

    return {
      results,
      summary: {
        totalImages: images.length,
        photosWithIssues,
        photosOk,
        processingTime: totalProcessingTime,
        // Legacy fields
        averageScore: photosWithIssues === 0 ? 95 : 50,
        acceptableCount: photosOk,
        recommendedCount: photosOk
      }
    }
  }

  /**
   * Build the analysis prompt based on photo type
   */
  private buildAnalysisPrompt(options: ImageQualityAnalysisOptions): string {
    const { photoType, modelClass } = options

    const subjectType = modelClass === 'ANIMAL' ? 'animal' : 'pessoa'
    const photoDescription = this.getPhotoTypeDescription(photoType)

    return `## An√°lise de Foto para Treinamento de IA

**Foto:** ${photoDescription}
**Tipo de sujeito:** ${subjectType}

---

### üéØ Objetivo
Avaliar se a foto deve ser **APROVADA** ou **REPROVADA** para treino de um modelo de IA.

> **REGRA DE OURO:**
> Na d√∫vida, **APROVE**.
> S√≥ **REPROVE** se houver um problema **MUITO claro e GRAVE** que impe√ßa aprender o rosto/identidade.

> **Consist√™ncia √© obrigat√≥ria:**
> A mesma foto deve **sempre** receber a **mesma avalia√ß√£o**.

---

## ‚úÖ CRIT√âRIOS IDEAIS (b√¥nus ‚Äì n√£o obrigat√≥rios)
- Ombros para cima (close de rosto) **OU** cintura para cima **OU** corpo inteiro
- Olhando para a c√¢mera (ou levemente de lado)
- Pessoa/animal √© o foco principal da foto

---

## üî¥ REPROVAR ‚Äî **APENAS se for MUITO claro**

${subjectType === 'pessoa' ? `### üîπ Se o sujeito for **PESSOA**
Reprove **somente** se ocorrer **pelo menos 1 item abaixo**, de forma clara:

- Imagem **claramente gerada por IA** (arte digital, pele irreal, inconsist√™ncias evidentes).
- **Outra pessoa** com o **rosto claramente vis√≠vel e n√≠tido**, ocupando parte relevante da imagem.
  - ‚úÖ **Permita** se a outra pessoa estiver desfocada, ao fundo, de costas, cortada ou irreconhec√≠vel.
- **Filtros pesados** (Snapchat/AR): distor√ß√µes, embelezamento extremo.
- **Careta extrema** que deforma o rosto (l√≠ngua para fora, olhos arregalados, boca exageradamente aberta).
- **Desfoque severo**: n√£o d√° para distinguir olhos, nariz e boca.
- **Qualidade muito baixa**: pixeliza√ß√£o grave **OU** rosto muito pequeno (< ~80‚Äì100px de altura).
- **Corte cr√≠tico do rosto**: falta testa **OU** falta queixo **OU** ambos os olhos n√£o aparecem.
- **Oclus√£o grande**: ~40% ou mais do rosto coberto **OU** olhos/nariz encobertos.
- **Ilumina√ß√£o extrema**: rosto quase invis√≠vel ou estourado a ponto de apagar detalhes.
- **√ìCULOS ESCUROS**: qualquer tipo que esconda os olhos.
- **BON√â / CHAP√âU / GORRO**: qualquer tipo que esconda a testa/linha do cabelo de forma relevante.` : `### üîπ Se o sujeito for **ANIMAL**
Reprove **somente** se ocorrer **pelo menos 1 item abaixo**, de forma clara:

- **M√∫ltiplos animais** claramente vis√≠veis como sujeitos principais.
- **Pessoas muito vis√≠veis e n√≠tidas** competindo com o animal.
- **Fantasias/roupas exageradas** que alterem a apar√™ncia real do animal.
- Animal **dormindo/olhos fechados**, sem visual claro do rosto.
- **Desfoque severo** ou **ilumina√ß√£o extrema** que impe√ßa ver os tra√ßos.`}

---

## üü° ALERTAS (N√ÉO reprovar ‚Äî apenas registrar, se quiser)
Marque como **alerta**, mas **APROVE**, quando houver:

- Sombra parcial no rosto, **desde que** olhos/nariz/boca sejam reconhec√≠veis.
- Luz dura, contraluz moderado, ilumina√ß√£o "imperfeita".
- Leve desfoque, granula√ß√£o ou compress√£o.
- Rosto levemente de lado (perfil 3/4), selfie normal.
- Objeto/m√£o cobrindo pouco do rosto (n√£o esconder os dois olhos).
- Peda√ßo de outra pessoa aparecendo **sem** rosto reconhec√≠vel.
- Pessoa ao fundo **sem** competir com o sujeito.

---

## ‚úÖ ACEIT√ÅVEL ‚Äî exemplos expl√≠citos
- Sombras fortes no rosto **com tra√ßos vis√≠veis** ‚úÖ
- Parte de outra pessoa **sem rosto reconhec√≠vel** ‚úÖ
- Praia, sol forte, sombra de √°rvore/coqueiro ‚úÖ
- Crian√ßa/beb√™ parcialmente aparecendo **sem competir** ‚úÖ
- Express√µes normais: sorrindo, s√©rio, rindo ‚úÖ
- √ìculos de grau **transparentes** ‚úÖ

---

Responda APENAS em JSON v√°lido (sem markdown):
{
  "hasIssues": <true APENAS se houver problema GRAVE E √ìBVIO que impe√ßa o treino, false se OK ou duvidoso>,
  "criticalIssues": [<array com c√≥digos: "ai_generated", "multiple_people", "making_faces", "heavy_filters", "low_light", "blurry", "hat_or_cap", "sunglasses", "extreme_angle", "face_cut_off", "low_quality", "face_covered">],
  "minorIssues": [],
  "issuesSummary": "<se hasIssues=true, descreva APENAS os problemas graves de forma objetiva. Ex: '√ìculos escuros'. Se false, omita>"
}`
  }

  /**
   * Get photo type description in Portuguese
   */
  private getPhotoTypeDescription(photoType: string): string {
    switch (photoType) {
      case 'face':
        return 'rosto (close-up do rosto)'
      case 'half_body':
        return 'meio corpo (da cintura para cima)'
      case 'full_body':
        return 'corpo inteiro'
      default:
        return 'rosto'
    }
  }
}

// Singleton instance for use across the application
export const imageQualityAnalyzer = new ImageQualityAnalyzer()
